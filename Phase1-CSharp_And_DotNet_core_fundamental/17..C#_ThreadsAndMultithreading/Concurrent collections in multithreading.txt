Concurrent collections
----------------------
Concurrent collections provide thread-safe implementations of common containers so multiple threads can read/write 
without you putting lock(...) around every access. They use fine-grained locking or lock-free algorithms internally for
better scalability and fewer bugs.

1) ConcurrentDictionary<TKey,TValue>

Use case: thread-safe cache, memoization, counters, or any shared lookup where multiple threads add/update/remove keys 
          concurrently.

# Most common methods : 

- GetOrAdd(key, valueFactory) ‚Äî add-if-missing atomically
- AddOrUpdate(key, addValueFactory, updateFactory) ‚Äî atomic add-or-update
- TryGetValue(key, out value) ‚Äî safe read
- TryRemove(key, out value) ‚Äî remove atomically
- TryUpdate(key, newValue, comparisonValue) ‚Äî conditional update

# Example : 

using System;
using System.Collections.Concurrent;
using System.Threading.Tasks;

var cache = new ConcurrentDictionary<string, int>();

// parallel to simulate 10 tasks 
Parallel.For(0, 10, i =>
{
    // atomic add-or-increment
    cache.AddOrUpdate("count", 1, (k, old) => old + 1);
    /*
        If "count" doesn‚Äôt exist ‚Üí insert "count" = 1.
        If "count" already exists ‚Üí update it using the function (k, old) => old + 1.
    */
});

if (cache.TryGetValue("count", out var total))
    Console.WriteLine($"count = {total}"); // expected 10


2) ConcurrentQueue<T>

Use case: lightweight, non-blocking FIFO queue for producer/consumer where order matters and consumers poll/dequeue items.

Most common methods : 

- Enqueue(item) ‚Äî push item
- TryDequeue(out item) ‚Äî pop item safely
- TryPeek(out item) ‚Äî look at head without removing
- IsEmpty / Count (Count is approximate under concurrency)

Example : 

using System;
using System.Collections.Concurrent;
using System.Threading.Tasks;

var q = new ConcurrentQueue<int>();

// producer
Task.Run(() => { for (int i = 0; i < 5; i++) q.Enqueue(i); });

// consumer
Task.Run(() =>
{
    int item;
    while (!q.IsEmpty || !Task.WaitAll()) // simplified demo loop
    {
        if (q.TryDequeue(out item))
            Console.WriteLine($"Dequeued {item}");
    }
});

3) ConcurrentStack<T>

Use case: LIFO scenarios (object pools, last-used-first reuse) where multiple threads push/pop concurrently.

Most common methods :

- Push(item) ‚Äî push on top
- TryPop(out item) ‚Äî pop top item
- TryPeek(out item) ‚Äî inspect top without removing
- ToArray() ‚Äî snapshot

Example : 

using System;
using System.Collections.Concurrent;

var stack = new ConcurrentStack<int>();
stack.Push(1);
stack.Push(2);

if (stack.TryPop(out var top))
    Console.WriteLine($"Popped {top}"); // 2


4) ConcurrentBag<T>

Use case: unordered thread-local-optimized collection for object pooling or when order doesn't matter. Good when threads mostly reuse their own items.

Most common methods : 

- Add(item) ‚Äî add an item
- TryTake(out item) ‚Äî remove an item (thread-local biased)
- TryPeek(out item) ‚Äî (if available in your framework) peek without removing
- ToArray() / Count ‚Äî snapshot / approximate count

Example : 

using System;
using System.Collections.Concurrent;
using System.Threading.Tasks;

var pool = new ConcurrentBag<byte[]>();

// producer: add reusable buffers
for (int i = 0; i < 5; i++) pool.Add(new byte[1024]);

// consumer: take a buffer, use it, then return it
Parallel.For(0, 10, i =>
{
    if (pool.TryTake(out var buf))
    {
        // use buffer...
        pool.Add(buf); // return for reuse
    }
    else
    {
        // allocate if none available
        var newBuf = new byte[1024];
        // use and return
        pool.Add(newBuf);
    }
});

5) BlockingCollection<T>

Use case: robust producer/consumer pipelines with optional bounding, blocking producers when full, and graceful shutdown
 (CompleteAdding). Often backed by ConcurrentQueue<T> by default.

Most common methods : 

- Add(item) / TryAdd(item, timeout) ‚Äî producer adds (blocks if bounded full)
- Take() / TryTake(out item, timeout) ‚Äî consumer removes (blocks if empty)
- CompleteAdding() ‚Äî signal no more items will be added
- GetConsumingEnumerable() ‚Äî iterate until completed (convenient consumer loop)

Example : 

using System;
using System.Collections.Concurrent; 
using System.Threading.Tasks;

var bc = new BlockingCollection<int>(boundedCapacity: 3);

// producer
var producer = Task.Run(() =>
{
    for (int i = 1; i <= 10; i++)
    {
        bc.Add(i); // blocks if capacity reached
        Console.WriteLine($"Produced {i}");
    }
    bc.CompleteAdding();
});

// consumer
var consumer = Task.Run(() =>
{
    foreach (var item in bc.GetConsumingEnumerable()) // stops when CompleteAdding + empty
        Console.WriteLine($"Consumed {item}");
});

The setup : 

You have a BlockingCollection<T> like this:

BlockingCollection<int> collection = new BlockingCollection<int>(boundedCapacity: 5);

Then you have two tasks:

// Producer
Task.Run(() =>
{
    for (int i = 0; i < 20; i++)
    {
        collection.Add(i);
        Console.WriteLine($"Produced: {i}");
    }
    collection.CompleteAdding();
});

// Consumer
Task.Run(() =>
{
    foreach (var item in collection.GetConsumingEnumerable())
    {
        Console.WriteLine($"Consumed: {item}");
        Thread.Sleep(500); // simulate slow consumer
    }
});

2Ô∏è‚É£ What happens when producer and consumer run
‚úÖ While the collection is not full

Producer calls Add(item) ‚Üí item is added immediately.
Consumer calls Take() or enumerates via GetConsumingEnumerable() ‚Üí consumes as soon as an item is available.

‚ö†Ô∏è When the collection reaches its bound (capacity)

If the collection has reached the bounded capacity,
then the next Add(item) call blocks (waits) until space becomes available.

The producer does not add new items beyond that bound.
It waits until the consumer removes at least one item.

3Ô∏è‚É£ When the consumer consumes

When the consumer takes an item (using Take() or the enumerator), the count decreases.
This frees up a slot in the bounded collection.
The producer‚Äôs blocked Add() call now unblocks and adds the next item.
So the producer and consumer are effectively synchronized ‚Äî the collection acts as a buffer between them.


| Time | Producer action                        | Collection contents | Consumer action |
| ---- | -------------------------------------- | ------------------- | --------------- |
| t0   | Add(1)                                 | [1]                 | ‚Äî               |
| t1   | Add(2)                                 | [1,2]               | ‚Äî               |
| t2   | Add(3)                                 | [1,2,3]             | ‚Äî               |
| t3   | Add(4) ‚Üí **blocks** (capacity reached) | [1,2,3]             | ‚Äî               |
| t4   | Consumer takes(1)                      | [2,3]               | frees 1 slot    |
| t5   | Producer‚Äôs blocked Add(4) completes    | [2,3,4]             | ‚Äî               |

Note : 

Work-Stealing in ConcurrentBag<T>
> Each thread has its own local bag.

> TryTake:

- First looks in the current thread‚Äôs bag (LIFO).
- If empty, it will steal from another thread‚Äôs bag (order undefined).

üëâ This "stealing" behavior is unique to ConcurrentBag<T> among the concurrent collections.


Other Concurrent Collections

1) ConcurrentQueue<T>

- Global FIFO queue (first in, first out).
- Items are stored in a single shared queue.
- Any thread can Enqueue or TryDequeue ‚Äî there‚Äôs no concept of "ownership".
- No stealing needed, because the data structure is already shared.

2) ConcurrentStack<T>

- Global LIFO stack (last in, first out).
- Any thread can Push or TryPop.
- Again, no stealing ‚Äî all items are in the same shared stack.

3) ConcurrentDictionary<TKey,TValue>

- Global hash table, divided internally into buckets.
- Any thread can TryAdd, TryUpdate, TryGetValue, TryRemove.
- Ownership doesn‚Äôt exist here either.

Only ConcurrentBag<T> has the concept of "per-thread local collection" and therefore may take items from another thread‚Äôs
The other collections are global, so all threads are always taking from the same shared structure.

