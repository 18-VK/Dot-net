Concurrent collections
----------------------
Concurrent collections provide thread-safe implementations of common containers so multiple threads can read/write 
without you putting lock(...) around every access. They use fine-grained locking or lock-free algorithms internally for
better scalability and fewer bugs.

1) ConcurrentDictionary<TKey,TValue>

Use case: thread-safe cache, memoization, counters, or any shared lookup where multiple threads add/update/remove keys 
          concurrently.

# Most common methods : 

- GetOrAdd(key, valueFactory) â€” add-if-missing atomically
- AddOrUpdate(key, addValueFactory, updateFactory) â€” atomic add-or-update
- TryGetValue(key, out value) â€” safe read
- TryRemove(key, out value) â€” remove atomically
- TryUpdate(key, newValue, comparisonValue) â€” conditional update

# Example : 

using System;
using System.Collections.Concurrent;
using System.Threading.Tasks;

var cache = new ConcurrentDictionary<string, int>();

// parallel to simulate 10 tasks 
Parallel.For(0, 10, i =>
{
    // atomic add-or-increment
    cache.AddOrUpdate("count", 1, (k, old) => old + 1);
    /*
        If "count" doesnâ€™t exist â†’ insert "count" = 1.
        If "count" already exists â†’ update it using the function (k, old) => old + 1.
    */
});

if (cache.TryGetValue("count", out var total))
    Console.WriteLine($"count = {total}"); // expected 10


2) ConcurrentQueue<T>

Use case: lightweight, non-blocking FIFO queue for producer/consumer where order matters and consumers poll/dequeue items.

Most common methods : 

- Enqueue(item) â€” push item
- TryDequeue(out item) â€” pop item safely
- TryPeek(out item) â€” look at head without removing
- IsEmpty / Count (Count is approximate under concurrency)

Example : 

using System;
using System.Collections.Concurrent;
using System.Threading.Tasks;

var q = new ConcurrentQueue<int>();

// producer
Task.Run(() => { for (int i = 0; i < 5; i++) q.Enqueue(i); });

// consumer
Task.Run(() =>
{
    int item;
    while (!q.IsEmpty || !Task.WaitAll()) // simplified demo loop
    {
        if (q.TryDequeue(out item))
            Console.WriteLine($"Dequeued {item}");
    }
});

3) ConcurrentStack<T>

Use case: LIFO scenarios (object pools, last-used-first reuse) where multiple threads push/pop concurrently.

Most common methods :

- Push(item) â€” push on top
- TryPop(out item) â€” pop top item
- TryPeek(out item) â€” inspect top without removing
- ToArray() â€” snapshot

Example : 

using System;
using System.Collections.Concurrent;

var stack = new ConcurrentStack<int>();
stack.Push(1);
stack.Push(2);

if (stack.TryPop(out var top))
    Console.WriteLine($"Popped {top}"); // 2


4) ConcurrentBag<T>

Use case: unordered thread-local-optimized collection for object pooling or when order doesn't matter. Good when threads mostly reuse their own items.

Most common methods : 

- Add(item) â€” add an item
- TryTake(out item) â€” remove an item (thread-local biased)
- TryPeek(out item) â€” (if available in your framework) peek without removing
- ToArray() / Count â€” snapshot / approximate count

Example : 

using System;
using System.Collections.Concurrent;
using System.Threading.Tasks;

var pool = new ConcurrentBag<byte[]>();

// producer: add reusable buffers
for (int i = 0; i < 5; i++) pool.Add(new byte[1024]);

// consumer: take a buffer, use it, then return it
Parallel.For(0, 10, i =>
{
    if (pool.TryTake(out var buf))
    {
        // use buffer...
        pool.Add(buf); // return for reuse
    }
    else
    {
        // allocate if none available
        var newBuf = new byte[1024];
        // use and return
        pool.Add(newBuf);
    }
});

5) BlockingCollection<T>

Use case: robust producer/consumer pipelines with optional bounding, blocking producers when full, and graceful shutdown
 (CompleteAdding). Often backed by ConcurrentQueue<T> by default.

Most common methods : 

- Add(item) / TryAdd(item, timeout) â€” producer adds (blocks if bounded full)
- Take() / TryTake(out item, timeout) â€” consumer removes (blocks if empty)
- CompleteAdding() â€” signal no more items will be added
- GetConsumingEnumerable() â€” iterate until completed (convenient consumer loop)

Example : 

using System;
using System.Collections.Concurrent;
using System.Threading.Tasks;

var bc = new BlockingCollection<int>(boundedCapacity: 3);

// producer
var producer = Task.Run(() =>
{
    for (int i = 1; i <= 10; i++)
    {
        bc.Add(i); // blocks if capacity reached
        Console.WriteLine($"Produced {i}");
    }
    bc.CompleteAdding();
});

// consumer
var consumer = Task.Run(() =>
{
    foreach (var item in bc.GetConsumingEnumerable()) // stops when CompleteAdding + empty
        Console.WriteLine($"Consumed {item}");
});

Task.WaitAll(producer, consumer);

Note : 

Work-Stealing in ConcurrentBag<T>
> Each thread has its own local bag.

> TryTake:

- First looks in the current threadâ€™s bag (LIFO).
- If empty, it will steal from another threadâ€™s bag (order undefined).

ðŸ‘‰ This "stealing" behavior is unique to ConcurrentBag<T> among the concurrent collections.


Other Concurrent Collections

1) ConcurrentQueue<T>

- Global FIFO queue (first in, first out).
- Items are stored in a single shared queue.
- Any thread can Enqueue or TryDequeue â€” thereâ€™s no concept of "ownership".
- No stealing needed, because the data structure is already shared.

2) ConcurrentStack<T>

- Global LIFO stack (last in, first out).
- Any thread can Push or TryPop.
- Again, no stealing â€” all items are in the same shared stack.

3) ConcurrentDictionary<TKey,TValue>

- Global hash table, divided internally into buckets.
- Any thread can TryAdd, TryUpdate, TryGetValue, TryRemove.
- Ownership doesnâ€™t exist here either.

Only ConcurrentBag<T> has the concept of "per-thread local collection" and therefore may take items from another threadâ€™s
The other collections are global, so all threads are always taking from the same shared structure.

